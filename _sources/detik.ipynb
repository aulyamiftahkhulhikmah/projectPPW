{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPdQLLgh4f/q12SbH6zr5Oq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0g3qaexc8RFl"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","def scrape_detik(category):\n","    all_data = []\n","    page = 1\n","\n","    while True:\n","        url = f'https://www.detik.com/search/searchnews?query={category}&sortby=time&page={page}'\n","        req = requests.get(url)\n","        sop = BeautifulSoup(req.text, 'html.parser')\n","        articles_container = sop.find('div', class_='list media_rows list-berita')\n","\n","        # Cek apakah halaman berikutnya masih tersedia\n","        if articles_container is None:\n","            break\n","\n","        articles = articles_container.find_all('article')\n","\n","        for article in articles:\n","            link = article.find('a')['href']\n","            date = article.find('a').find('span', class_='date').text.replace('WIB', '').replace('detikNews', '').split(',')[1]\n","            headline = article.find('a').find('h2').text\n","\n","            ge_ = requests.get(link).text\n","            sop_ = BeautifulSoup(ge_, 'html.parser')\n","            content = sop_.find('div', class_='detail__body-text itp_bodycontent')\n","\n","            # Pengecekan apakah content memiliki nilai None\n","            if content:\n","                paragraphs = content.find_all('p')\n","                content_ = ''.join([p.get_text(strip=True) for p in paragraphs])\n","            else:\n","                content_ = ''\n","\n","            all_data.append({\n","                'category': category,\n","                'headline': headline,\n","                'date': date,\n","                'content': content_\n","            })\n","\n","        page += 1\n","\n","    return all_data\n","\n","# Daftar kategori\n","categories = ['pemilu+2024', 'your_second_category', 'your_third_category']\n","\n","# Lakukan crawling data untuk setiap kategori\n","all_data = []\n","\n","for category in categories:\n","    category_data = scrape_detik(category)\n","    all_data.extend(category_data)\n","\n","# Simpan data ke CSV\n","csv_file_path = 'detik_news_data.csv'\n","csv_columns = ['category', 'headline', 'date', 'content']\n","\n","with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n","    writer = csv.DictWriter(csv_file, fieldnames=csv_columns)\n","    writer.writeheader()\n","    for data in all_data:\n","        writer.writerow(data)\n","\n","print(f'Data telah disimpan ke {csv_file_path}')"]}]}